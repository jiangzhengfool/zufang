{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2CDEEBA926B488A8156EFBE9F5A23B7",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0AA02EF5A8514E94A2DD197C3AF46B4F",
    "jupyter": {},
    "notebookId": "6065b0eead50140017676782",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "gc.enable()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "#读取训练集与测试集并构建原始数据\n",
    "train = pd.read_csv('./train.csv').sample(frac=1)\n",
    "test = pd.read_csv('./test.csv')\n",
    "df_features = train.append(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['洗手间数量'].fillna(-1, inplace=True)\n",
    "df_features['床的数量'].fillna(-1, inplace=True)\n",
    "df_features['卧室数量'].fillna(-1, inplace=True)\n",
    "df_features['房主是否有个人资料图片'].fillna('na', inplace=True)\n",
    "df_features['房主身份是否验证'].fillna('na', inplace=True)\n",
    "df_features['房主回复率'].fillna('-1', inplace=True)\n",
    "df_features['房主回复率'] = df_features['房主回复率'].astype(str).apply(lambda x: x.replace('%', ''))\n",
    "df_features['房主回复率'] = df_features['房主回复率'].astype(int)\n",
    "df_features['民宿周边'].fillna('na', inplace=True)\n",
    "mean_score = df_features['民宿评分'].mean()\n",
    "df_features['民宿评分'].fillna(mean_score, inplace=True)\n",
    "df_features['邮编'].fillna('na', inplace=True)\n",
    "\n",
    "for feat in ['房主是否有个人资料图片', '房主身份是否验证', '民宿周边', '邮编']:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(df_features[feat])\n",
    "    df_features[feat] = lbl.transform(df_features[feat])\n",
    "\n",
    "def freq_enc(df, col):\n",
    "    vc = df[col].value_counts(dropna=True, normalize=True).to_dict()\n",
    "    df[f'{col}_freq'] = df[col].map(vc)\n",
    "    return df\n",
    "\n",
    "for feat in ['容纳人数', '洗手间数量', '床的数量', '床的类型',\n",
    "             '卧室数量', '取消条款', '所在城市', '清洁费',\n",
    "             '房主是否有个人资料图片', '房主回复率', '是否支持随即预订',\n",
    "             '民宿周边', '房产类型', '房型', '邮编']:\n",
    "    df_features = freq_enc(df_features, feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# 时间特征处理\n",
    "from tqdm import tqdm\n",
    "df_features['首次评论日期'] = pd.to_datetime(df_features['首次评论日期']).values.astype(np.int64) // 10 ** 9\n",
    "df_features['何时成为房主'] = pd.to_datetime(df_features['何时成为房主']).values.astype(np.int64) // 10 ** 9\n",
    "df_features['最近评论日期'] = pd.to_datetime(df_features['最近评论日期']).values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "df_features['timestamp_diff1'] = df_features['首次评论日期'] - df_features['何时成为房主']\n",
    "df_features['timestamp_diff2'] = df_features['最近评论日期'] - df_features['首次评论日期']\n",
    "df_features['timestamp_diff3'] = df_features['最近评论日期'] - df_features['何时成为房主']\n",
    "\n",
    "def brute_force(df, features, groups):\n",
    "    for method in tqdm(['max', 'min', 'mean', 'median', 'std']):\n",
    "        for feature in features:\n",
    "            for group in groups:\n",
    "                df[f'{group}_{feature}_{method}'] = df.groupby(group)[feature].transform(method)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dense_feats = ['timestamp_diff1', 'timestamp_diff2', 'timestamp_diff3']\n",
    "cate_feats  = ['房型']\n",
    "\n",
    "df_features = brute_force(df_features, dense_feats, cate_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "df_features['if_bed'] = train['床的数量'].apply(f)\n",
    "df_features['if_bedroom'] = train['卧室数量'].apply(f)\n",
    "df_features['if_wc'] = train['洗手间数量'].apply(f)\n",
    "\n",
    "#交叉衍生特征\n",
    "df_features['人均床数量'] = df_features['容纳人数'] / (df_features['床的数量'] + 1e-3)  # 1e-3 是为了避免 zero-divide\n",
    "df_features['人均卧室量'] = df_features['容纳人数'] / (df_features['卧室数量'] + 1e-3)\n",
    "df_features['卧室床均量'] = df_features['床的数量'] / (df_features['卧室数量'] + 1e-3)\n",
    "df_features['经纬度平方根'] = (df_features['维度']*df_features['维度'] + df_features['经度']*df_features['经度'])**.5\n",
    "\n",
    "def get_features(df):\n",
    "    features = [['人均床数量','人均卧室量'],['卧室床均量','人均卧室量']]\n",
    "    for fea in features:\n",
    "        df[f'{fea[0]}_{fea[1]}_std'] = df[fea].std(1)\n",
    "        df[f'{fea[0]}_{fea[1]}_max'] = df[fea].max(1)\n",
    "        df[f'{fea[0]}_{fea[1]}_min'] = df[fea].min(1)\n",
    "\n",
    "        df[f'{fea[0]}_{fea[1]}_sub'] = df[fea[0]] - df[fea[1]]\n",
    "\n",
    "        #df.loc[df[fea[0]] <= df[fea[1]],f'{fea[0]}_{fea[1]}_mark'] = 0\n",
    "        #df.loc[df[fea[0]] > df[fea[1]],f'{fea[0]}_{fea[1]}_mark'] = 1 \n",
    "    return df\n",
    "\n",
    "df_features = get_features(df_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "df_features['便利设施数量']=df_features['便利设施'].apply(lambda x:len(x.lstrip('{').rstrip('}').split(',')))\n",
    "df_features['便利设施'] = df_features['便利设施'].apply(\n",
    "    lambda x: x.replace('{', '').replace('}', '').replace('\"', '').replace(':', '').replace(',', ' '))\n",
    "# df_features['便利设施'] = df_features['便利设施'].str.lower()\n",
    "\n",
    "n_components = 12\n",
    "\n",
    "X = list(df_features['便利设施'].values)\n",
    "tfv = TfidfVectorizer(ngram_range=(1,1), max_features=10000)\n",
    "tfv.fit(X)\n",
    "X_tfidf = tfv.transform(X)\n",
    "svd = TruncatedSVD(n_components= n_components)\n",
    "svd.fit(X_tfidf)\n",
    "X_svd = svd.transform(X_tfidf)\n",
    "\n",
    "for i in range(n_components):\n",
    "    df_features[f'便利设施_tfidf_{i}'] = X_svd[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_features[~df_features['价格'].isnull()]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_features[df_features['价格'].isnull()]\n",
    "\n",
    "no_features = ['数据ID', '价格', '便利设施']\n",
    "# 输入特征列\n",
    "features = [col for col in df_train.columns if col not in no_features]\n",
    "\n",
    "X = df_train[features] # 训练集输入\n",
    "y =y_train = df_train['价格'] # 训练集标签\n",
    "X_test = df_test[features] # 测试集输入\n",
    "test_Id =  df_test['数据ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=Lasso(alpha=0.001)\n",
    "lasso.fit(X[features],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_model = CatBoostRegressor(iterations=60000, # 注：baseline 提到的分数是用 iterations=60000 得到的，但运行时间有点久\n",
    "                           learning_rate=0.2, # 注：事实上好几个 property 在 lr=0.1 时收敛巨慢。后面可以考虑调大\n",
    "                           eval_metric='SMAPE',\n",
    "#                            use_best_model=True,\n",
    "                           random_seed=42,\n",
    "                           verbose=0,\n",
    "                        silent=None,\n",
    "                        logging_level=None,\n",
    "                           #task_type='GPU',\n",
    "                           devices='0',\n",
    "                           gpu_ram_part=0.5,\n",
    "                           early_stopping_rounds=4000)\n",
    "# lasso/ElasticNet模型对异常值敏感，使用RobustScaler缩放有离群值的数据\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=0.25)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.2,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.2, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=5000,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, \n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.2, n_estimators=5000,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "def nmse_cv(model):\n",
    "    kf = KFold(n_splits, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    nmse = np.sqrt(-cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kf,verbose=50))\n",
    "    return(nmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-69.565, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.3s remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-44.011, total=  19.8s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.2s remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-41.390, total=  25.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-39.819, total=  21.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-42.851, total=  29.7s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.9min finished\n",
      "lasso score:6.8529 (0.7517) \n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-69.641, total=  26.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.3s remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-44.012, total=  25.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   51.7s remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-41.391, total=  24.8s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-39.820, total=  23.5s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=-42.851, total=  21.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "ENet score:6.8538 (0.7535) \n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV]  ................................................................\n"
     ]
    }
   ],
   "source": [
    "models = [lasso,ENet,cbt_model,KRR, model_xgb, model_lgb]\n",
    "names = ['lasso','ENet','catboot','KRR', 'Xgboost', 'LGBM']\n",
    "for model, name in zip(models, names):\n",
    "    score = nmse_cv(model)\n",
    "    # 验证结果返回5个分数，求均值和标准差\n",
    "    print('{} score:{:.4f} ({:.4f}) \\n'.format(name, score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        \n",
    "    # 将原来的模型clone出来，并且实现fit功能    \n",
    "    def fit(self, X, y):\n",
    "        self.clone_base_models = [list() for x in self.base_models]\n",
    "        self.clone_meta_model = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "      \n",
    "        # 使用K-fold的方法来进行交叉验证，将每次验证的结果作为新的特征来进行处理\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, test_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.clone_base_models[i].append(instance)\n",
    "                \n",
    "                instance.fit(X.iloc[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X.iloc[test_index])\n",
    "                out_of_fold_predictions[test_index, i] = y_pred\n",
    "                \n",
    "        # 将交叉验证预测出的结果(标签)和训练集中的标签值用元模型进行训练\n",
    "        self.clone_meta_model.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # 得到各模型预测结果平均值的二维数组\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.clone_base_models\n",
    "        ])\n",
    "        return self.clone_meta_model.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models=( lasso,ENet,cbt_model,KRR model_xgb, model_lgb), meta_model=lasso)\n",
    "# score = nmse_cv(stacked_averaged_models)\n",
    "# print('Stacking Averaged models score: {:.4f} ({:.4f})'.format(score.mean(), score.std()))\n",
    "# 结果模型叠加分数比模型平均分数更低，模型效果更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方差：MSE的值越小，预测模型具有更好的精确度\n",
    "def mse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(X[features], y)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X[features])\n",
    "# 前面用log1p函数转化使标签更加服从高斯分布，现用expm1将预测出的平滑数据进行还原\n",
    "# stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "stacked_pred = (stacked_averaged_models.predict(X_test))\n",
    "print(mse(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(X, y)\n",
    "xgb_train_pred = model_xgb.predict(X)\n",
    "# xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "xgb_pred = (model_xgb.predict(X_test))\n",
    "print(mse(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "#                               learning_rate=0.2, n_estimators=720,\n",
    "#                               max_bin = 55, )\n",
    "model_lgb.fit(X, y)\n",
    "lgb_train_pred = model_lgb.predict(X)\n",
    "# lgb_pred = np.expm1(model_lgb.predict(test))\n",
    "lgb_pred = (model_lgb.predict(X_test))\n",
    "\n",
    "print(mse(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于交叉验证分数给出权重\n",
    "# Xgboost score:0.1161 (0.0079) \n",
    "# LGBM score:0.1167 (0.0072) \n",
    "# Stacking Averaged models score: 0.1084 (0.0073)\n",
    "print('MSE score on train data:')\n",
    "print(mse(y_train, stacked_train_pred*0.60 + xgb_train_pred*0.3 + lgb_train_pred*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*1\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['数据ID'] = test_Id\n",
    "sub['价格'] = ensemble\n",
    "sub.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
